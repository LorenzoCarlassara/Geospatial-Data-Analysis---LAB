%% Geospatial Data Analysis - Lab Assignment
% Student: Lorenzo Carlassara 101724
%
% The provided time series are real data made available by ARPA Veneto, the regional agency for environment protection. 
% The whole dataset is composed by measurements from several boreholes each identified by a numeric ID. 
% 
% The following project takes in consideration only a borehole, in
% particular one carrying a large amount of time samples, regardless it can be exentend to all the wells.
%% Data Preprocessing
% The missing values are removed from the data table and they will be replaced if needed;  
% the features used are:
%%
% * epochs 'DATA' converted upstream in integer numbers;
% * piezometer measurements 'LIVELLOSTATICO [mslm]' taken between 1999 and
% 2021 (roughly);
% * boreholds ID planar cartographic coordinates in the district of Padua;
% * altitude of the boreholds ID 'QUOTA P.R. [mslm]';
% * interpolated equidistant epochs;
close all, clear all, addpath('C:\Users\Utente\Documents\Matlab\MatLabWorks\GDA\')
% pz = readtable('Sotterranee_livello_piezometrico_PD_1999_2021.csv');
% pz = pz(~any(ismissing(pz),2),:);
% an = readtable('anagrafica_Sotterranee_livello_piezometrico_PD_1999_2021.csv');
% an_ = an.N_POZZO(~isnan(an.QUOTAP_R__mslm_));
% an = readtable('anagrafica_Sotterranee_livello_piezometrico_PD_1999_2021.csv'); 
% coord_z = an.QUOTAP_R__mslm_(~isnan(an.QUOTAP_R__mslm_));
% coord_xy(length(an_)+1:end,:) = [];
% save PZ.mat
load PZ.mat 
% help Find_Pol
% help LS
% help Pol_Interp
% help Exact_Cubic_Spline
% help Cubic_Spline
% help Cubic_Spline_2D
% help CovMatrix
% help CovFunction
figure;
for id = 1:length(an_)
   plot(datetime(86400*(pz.dataEpoch(pz.N_POZZO == an_(id))-1),...
   'ConvertFrom','epochtime','Epoch','1999-01-01','Format','dd/MMM/yyyy'),...
   pz.LIVELLOSTATICO_MS_l_m_(pz.N_POZZO == an_(id))), hold on 
end
id = 14; 
%for id = 14:18%length(an_)
x_obs = pz.dataEpoch(pz.N_POZZO == an_(id));
f_obs = pz.LIVELLOSTATICO_MS_l_m_(pz.N_POZZO == an_(id));
x_syn = (x_obs(1):x_obs(end))';
h_obs = (x_obs(1)+1:91.25:x_obs(end))';
x_dt = datetime(86400*(x_obs-1),'ConvertFrom','epochtime','Epoch','1999-01-01','Format','dd/MMM/yyyy');
h_dt = datetime(86400*(h_obs-1),'ConvertFrom','epochtime','Epoch','1999-01-01','Format','dd/MMM/yyyy');
s_dt = datetime(86400*(x_syn-1),'ConvertFrom','epochtime','Epoch','1999-01-01','Format','dd/MMM/yyyy');
n_pz = sprintf(' ID %d',an_(id));
%% Smoothing Least Square Interpolation
% Find the best fitting polynomial with a low degree using a treshold on
% the ratio between consecutive polynomials of dregree _k_ and _k+1_ until
% the improvement is too low.
% 
% Once obtained the best number of parameters for the Smoothing Least Square
% Interpolation, the polynomial model is build computing the optimum
% solution that minimize the residuals.
%
% The polynomial describes the overall overview of the samples behaviour
% and, assuming this as the deterministic component of the given
% samples, it will be deployed later on the further analysis.

trsh = 0.0001; 
[best, err] = Find_Pol(x_obs, f_obs, trsh);

params = best; 
F = Pol_Interp(x_obs, params); 
a_hat = LS(F,f_obs);  
F_interp = Pol_Interp(x_syn,params);
f_LS = F_interp*a_hat;

figure
hold on
deg = sprintf('polynomial degree: %d',params-1);
title("LS Polynomial Interpolation" + n_pz)
plot(s_dt,f_LS,'Color',[0.8500 0.3250 0.0980]);
plot(x_dt,f_obs,'o','Color',[0 0.4470 0.7410]); grid on;
xlabel('years'), ylabel('[m]'), legend(deg,"measurements",'Location','best')
hold off
%% Exact Cubic Spline
% Each timeseries covers a different period and although there are  4 times per year 
% the dates of acquisition are different.
% In order to get an equally distant interval of sampling and fill the holes 
% provided by the missing values, Exact Cubib Spline is a smooth suitable
% interpolation method based on a polynomial of third order in the Newton
% form.
[f_h, x_h] = Exact_Cubic_Spline(x_obs,f_obs,h_obs);

figure, plot(h_dt,f_h,'-*','Color',[0.8500 0.3250 0.0980]) 
title("Exact Interpolation" + n_pz)
hold on, plot(x_dt,f_obs,'o','Color',[0 0.4470 0.7410]); grid on;
xlabel('years'), ylabel('[m]'),legend('equidistant cubic spline',"measurements",'Location','best')
% exact cubic spline fails with a large gap of missing data, in this case
% performing a LS interpolation is more suitable

% When the profiles were homogeneous both methods performed well, but when theprofiles   
% were   heterogeneous,   linear   interpolation   generally   performed   better   
% than   cubic   spline   interpolation.Although the data generated by cubic spline 
% interpolation were less biased than those generated by linear inter-polation, there 
% were more instances of extreme errors. The results of this study suggest that linear 
% interpolationis generally preferable to cubic spline interpolation for filling data gaps 
% in measured lake water column profiles
%% Discrete Fourier Transformation
% Assuming the provided piezometer measurements to be samples of a signal
% that can be decomposed in a finite sum of sin and cosine functions. 
% 
% The resulting equidistant sampling got by the Exact Spline is required
% to build the power spectrum of the signal.
% 
% The power spectrum shows that there is no clear evidence to say if the
% frequencies are noise or harmonic component for example at 6 months.

% figure,
% plot(h_dt,f_h,'o-','Color',[0.8500 0.3250 0.0980]), grid on
% legend('obs'), title("signals (time domain)" + n_pz), xlabel('years'), ylabel('[m]')
N = length(h_obs);
if (mod(N,2)==0) %even   
    f = 1/N * (-N/2 : N/2-1)'; 				% intervall [-fs/2 , fs/2]
else             %odd
	f = 1/N * (-(N-1)/2 : (N-1)/2)'; 		% intervall [-fs/2 , fs/2]
end
Fobs1 = 1/N * fftshift(fft(f_h));	% Fourier transformation

Fobs = (abs(Fobs1) - min(abs(Fobs1)))/(max(abs(Fobs1))-min(abs(Fobs1)));
figure
plot(f,abs(Fobs1),'x-','Color',[0 0.4470 0.7410])
title('Fourier transform (power spectra)')
xlabel('frequency'),grid on
ylim([0,1])
deg = sprintf('obs signal - a0 = %g',max(abs(Fobs1)));
legend(deg,'Location','best')
% exact cubic spline fails with a large gap of missing data, in this case
% performing a LS interpolation is more suitable
%
% there is no a clear coefficient of the frequency component that can be removed from data

%% Collocation Technique 
% # Empirical covariance function estimation by computing the residuals
% # Covariance model parameters by exact polynomial interpolation
% # Filter samples using the evaluated ECF model

% Assuming that the polynomial interpolation catches all the deterministic 
% component that characterizes the Random Process
f_LS = Pol_Interp(x_obs, params)*a_hat;
f_obs_nomean = f_obs - f_LS;
figure, plot(x_dt,f_obs_nomean), title("Residuals" + n_pz)
xlabel('years'), ylabel('[m]')

% Compute obs lag matrix
[t1,t2] = meshgrid(x_obs,x_obs);
TAO = abs(t1-t2);
TAO = triu(TAO,1);

% Compute correspondent obs cov matrix
[p1,p2] = meshgrid(f_obs_nomean,f_obs_nomean);
C = p1.*p2;
C = triu(C,1);

%Reshape lag and cov into arrays 
tao = TAO(:);
c = C(:);

% Consider single combinations only
c(tao==0)=[];
tao(tao==0)=[];

% Empirical covariance (ECF) computation
delta_tao_ecf =365;		                       %ECF sampling interval: 1 year
max_tao_ecf = max(x_obs)/2;			               %farther ECF sample: half of the time span
tao_ecf = 0:delta_tao_ecf:max_tao_ecf;			    %ECF tao bin edges
tao_inbin = discretize(tao,tao_ecf);					%ECF tao binning
ECF=[];
for bin = 1:length(tao_ecf)-1							%ECF tao binning
	c_inbin = c(tao_inbin==bin);
	ECF(bin,1) = tao_ecf(bin)+ delta_tao_ecf/2;
	ECF(bin,2) = mean(c_inbin);
end
ECF = [[0 var(f_obs_nomean)]; ECF];						%add C(0) to ECF

figure
plot(ECF(:,1),ECF(:,2),'*b'), grid on, hold on
xlabel('days')
delta_tao_ecf =365/2;		                       %ECF sampling interval: 1 year
max_tao_ecf = max(x_obs)/2;			               %farther ECF sample: half of the time span
tao_ecf = 0:delta_tao_ecf:max_tao_ecf;			    %ECF tao bin edges
tao_inbin = discretize(tao,tao_ecf);					%ECF tao binning
ECF=[];
for bin = 1:length(tao_ecf)-1							%ECF tao binning
	c_inbin = c(tao_inbin==bin);
	ECF(bin,1) = tao_ecf(bin)+ delta_tao_ecf/2;
	ECF(bin,2) = mean(c_inbin);
end
ECF = [[0 var(f_obs_nomean)]; ECF];		

plot(ECF(:,1),ECF(:,2),'*r'),title("Empirical Covariance Function" + n_pz)
xlabel('distance [days]')

% Exact Polynomial interpolation
x_emp = ECF(2:4,1);
f_emp = ECF(2:4,2);
K = zeros(length(x_emp),length(x_emp)); % initialize design matrix
for i = 0:length(x_emp)-1
    K(:,i+1) = (x_emp).^i; % compute design matrix
end
u = K'*f_emp;
k_hat = inv(K'*K)*u;

A = k_hat(1); 
alpha = - log(ECF(2,2)/A)/2;

model = "Exponential";
sigma = A; len = alpha; % hyperparameters of the kernel function 

tau_ss = CovMatrix(x_obs); % matrix of the distances

Css = CovFunction(tau_ss,sigma,len,model); % covariance matrix

eps = 2^(-50); % prevent dividing by 0
noise = ECF(1,2)-A; % noise
C = (Css + (eps + noise)*eye(length(x_obs))); 

r_fil = Css' * (C\f_obs_nomean);

y_fil = Pol_Interp(x_obs,params)*a_hat + r_fil;
figure, plot(x_dt, f_obs,'o',x_dt,y_fil)
title("Empirical Covariance Model - " + model + n_pz)
xlabel('years'), ylabel('[m]'),legend('measurements','filtered model','Location','best')

%end

%% Kernel method for linear regression interpolation
% Comparison of the result provided by the Collocation ECF 
% with a priori assumption on the model distribution to be 
% the popular Normal model with hyperparameters provided by maximum
% likelihood estimator MLE

% The ecf is better

% find the hyperparameters of the kernel function using mle
model = "Normal";
phat = mle(f_obs, 'Distribution', model); 
sigma = phat(1); len = phat(2); 

 % Matrix of the distances
tau_ss = CovMatrix(x_obs);
tau_ps = CovMatrix(x_obs,x_obs); 
tau_pp = CovMatrix(x_syn);

% Covariance matrix
Css = CovFunction(tau_ss,sigma,len,model); 
Csp = CovFunction(tau_ps,sigma,len,model);
Cpp = CovFunction(tau_pp,sigma,len,model);

eps = 2^(-50); % prevent dividing by 0
noise = noise;   % noise
C = (Css + (eps + noise)*eye(length(x_obs))); 

L = chol(C)'; % Cholesky Decomposition
alfa = L'\(L\f_obs); %  L*L' = C
y_L = Csp'*alfa; 

y_pred = Csp' * (C\f_obs);

figure, plot(x_dt,y_pred,'*','Color',[0.8500 0.3250 0.0980])
hold on, plot(x_dt,f_obs,'o','Color',[0 0.4470 0.7410]) 
title("Random Process" + n_pz)
legend("prior: "+ model+" model",'measurements','Location','best')

f_obs_nomean = f_obs - y_pred;
figure, plot(x_dt,f_obs_nomean), title("Residuals" + n_pz)
xlabel('years'), ylabel('[m]')

% Compute correspondent obs cov matrix
[p1,p2] = meshgrid(f_obs_nomean,f_obs_nomean);
C = p1.*p2;
C = triu(C,1);

%Reshape lag and cov into arrays 
tao = TAO(:);
c = C(:);

% Consider single combinations only
c(tao==0)=[];
tao(tao==0)=[];

% Empirical covariance (ECF) computation
delta_tao_ecf =365;		                       %ECF sampling interval: 1 year
max_tao_ecf = max(x_obs)/2;			               %farther ECF sample: half of the time span
tao_ecf = 0:delta_tao_ecf:max_tao_ecf;			    %ECF tao bin edges
tao_inbin = discretize(tao,tao_ecf);					%ECF tao binning
ECF=[];
for bin = 1:length(tao_ecf)-1							%ECF tao binning
	c_inbin = c(tao_inbin==bin);
	ECF(bin,1) = tao_ecf(bin)+ delta_tao_ecf/2;
	ECF(bin,2) = mean(c_inbin);
end
ECF = [[0 var(f_obs_nomean)]; ECF];						%add C(0) to ECF

figure
plot(ECF(:,1),ECF(:,2),'*b'), grid on
title("Empirical Covariance Function" + n_pz)
xlabel('distance [days]')
delta_tao_ecf =365/2;		                       %ECF sampling interval: 1 year
max_tao_ecf = max(x_obs)/2;			               %farther ECF sample: half of the time span
tao_ecf = 0:delta_tao_ecf:max_tao_ecf;			    %ECF tao bin edges
tao_inbin = discretize(tao,tao_ecf);					%ECF tao binning
ECF=[];
for bin = 1:length(tao_ecf)-1							%ECF tao binning
	c_inbin = c(tao_inbin==bin);
	ECF(bin,1) = tao_ecf(bin)+ delta_tao_ecf/2;
	ECF(bin,2) = mean(c_inbin);
end
ECF = [[0 var(f_obs_nomean)]; ECF];		

hold on, plot(ECF(:,1),ECF(:,2),'*r')

model = "Exponential";
sigma = A; len = alpha; % hyperparameters of the kernel function 

tau_ss = CovMatrix(x_obs); % matrix of the distances

Css = CovFunction(tau_ss,sigma,len,model); % Empirical covariance matrix

eps = 2^(-50); % prevent dividing by 0
noise = ECF(1,2)-A; % noise
C = (Css + (eps + noise)*eye(length(x_obs))); 

r_fil = Css' * (C\f_obs_nomean);

y_fil = y_pred + r_fil;
figure, plot(x_dt, f_obs,'o',x_dt,y_fil)
title("Empirical Covariance Model - " + model + n_pz)
xlabel('years'), ylabel('[m]'),legend('measurements','filtered model','Location','best')

%% 2D LS Cubic Spline (3rd order mother spline)
% Exploring the data along time shows heterogeneous samples between borehols 
% Exploring the data along space shows that the water levels measurements 
% are uniform with the respective coordinates. Moreover, there isn't a particular evidence
% of changing in the shape of the levels over time.
%
% If the minimum numbers of boreholds required to describe the surface is 
% not satisfied may lead to twisted results
% 
% Anyway the reduction of boreholes seems to not affected the 2D
% interpolation until the number of samples are heavily decreased.

% original boreholes --> limit at 6 epochs
drop = [66 67 68 73 76 77 78]; % limit at 26 epochs
%drop = [66 67 68 73 76 77 78 79 82 83 84 85 87 515]; 
% not enough boreholes
for d = 1:length(drop)
    coord_xy(find(an_==drop(d)),:) = [];
    coord_z = coord_z(an_~=drop(d));
    an_ = an_(an_~=drop(d));
end
p = 6;
%for p = [1,20,21]
    f_lev=[];
    for id = 1:length(an_)
        x_day = pz.dataEpoch(pz.N_POZZO == an_(id));
        f_day = pz.LIVELLOSTATICO_MS_l_m_(pz.N_POZZO == an_(id));
        h_day = (1096:91.25:x_day(end))'; 
        % 1 = 01/01/1999, 1096 = 01/01/2002
        [f_xh, xh] = Exact_Cubic_Spline(x_day,f_day,h_day);
        f_lev(id,1) = f_xh(p);
    end
datet = datetime(86400*(xh(p)),'ConvertFrom','epochtime','Epoch','1999-01-01','Format','dd/MMM/yyyy');
x_coo = coord_xy(1:length(an_),1);
y_coo = coord_xy(1:length(an_),2);

figure
scatter(x_coo,y_coo,15,f_lev,'filled'),title("Observed data + spline knots " + datestr(datet,'dd/mmm/yyyy')),colorbar

h = (max(x_coo)-min(x_coo))/2;
h_y = (max(y_coo)-min(y_coo))/2;
x_spl = min(x_coo):h:max(x_coo);
y_spl = min(y_coo):h_y:max(y_coo);
[x_spl,y_spl] = meshgrid(x_spl,y_spl);
x_spl=x_spl(:);
y_spl=y_spl(:);
hold on,scatter(x_spl,y_spl,"+")
hold on,scatter(1.725*10^6,5.032*10^6,"diamond",'filled','k')
legend('boreholes','spline','Padua','Location','best')

num = 499;
x_synth = []; y_synth = [];
x_synth = min(x_coo):(max(x_coo)-min(x_coo))/num:max(x_coo);
y_synth = min(y_coo):(max(y_coo)-min(y_coo))/num:max(y_coo);
x_synth = x_synth + (mean(x_coo)-mean(x_synth));
y_synth = y_synth + (mean(y_coo)-mean(y_synth));
[x_synth,y_synth] = meshgrid(x_synth,y_synth);
x_synt=x_synth(:);
y_synt=y_synth(:);

F_spl2D = Cubic_Spline_2D(x_coo,x_spl,y_coo,y_spl,h,h_y);
F_pred = Cubic_Spline_2D(x_synt,x_spl,y_synt,y_spl,h,h_y);

a_lev = LS(F_spl2D,f_lev);
a_Z = LS(F_spl2D,coord_z);
f_interp = F_pred*a_lev;
f_z = F_pred*a_Z;
figure
scatter(x_synt,y_synt,15,f_interp,'filled')
xlim([min(x_synt) max(x_synt)]),ylim([min(y_synt) max(y_synt)]),title("Interpolated data " + datestr(datet,'dd/mmm/yyyy')),colorbar
hold on,scatter(1.725*10^6,5.032*10^6,"diamond",'filled','k')

F_interp = reshape(f_interp,sqrt(length(f_interp)),sqrt(length(f_interp)));
F_z = reshape(f_z,sqrt(length(f_z)),sqrt(length(f_z)));
figure
s=surf(x_synth,y_synth,F_z,F_interp);colorbar,set(s,'LineStyle','none')
zlabel('altitude [mslm]')
title("3D LS cubic spline " + datestr(datet,'dd/mmm/yyyy'))
%end
% bi-dimensional case --> 3 different reasons
% Padua lays on two different Watersheds
%% Brief conclusion
% The average water level in the catchment area of the Venice Lagoon is about 1 meter above sea level. 
% However, the water level can vary depending on tides, rainfall, and human activities, 
% such as the construction of hydraulic infrastructure.
% The average water level in the catchment area of the Brenta River basin depends on its cross section 
% and season. In the lower section, downstream from Padua, the average level is about 2 meters above sea level,
% while in the upper section, upstream from Bassano del Grappa, the average level is about 150 meters 
% above sea level. However, the water level can vary greatly due to heavy rainfall or drought.
%
% the root mean square error, mean bias error, and maximum absolute bias error 
% of the interpolated values in relation to the original measured values
%
% The developped script can be more accurate in some boreholes than other,
% due to the variety in the samples distribution between different time
% series. Considering clustering them could help
% Including more information about the data may be helpful, 
% for example adding some layers could help find a stronger pattern on the
% behaviour.
%
% A proposal for further analysis may be the implementation of Linearized LS on the hyperparameters
% and also the implementation of Kriging method. Furthermore,
% a comparison of the performance of different technique or different boreholes with evaluation metrics 
% (eg R-squared, R-squared adj, AIC, BIC)
% 
% Thanks for the attention